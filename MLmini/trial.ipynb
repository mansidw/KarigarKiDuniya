{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0bb11029e2afac0e7f6618262482e01595b9fa9c6642c63436503e9a1c447fc40",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "bb11029e2afac0e7f6618262482e01595b9fa9c6642c63436503e9a1c447fc40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from string import punctuation\n",
    "from scipy.sparse import vstack, hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iama girl\n"
     ]
    }
   ],
   "source": [
    "#####   removing punctuation    ######\n",
    "import string\n",
    "def remove_punctuation(sentence: str) -> str:\n",
    "    return sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "print(remove_punctuation(\"I,am!a girl.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hey boy! \n"
     ]
    }
   ],
   "source": [
    "########## removing digits     #########\n",
    "def remove_digits(x):\n",
    "    x = ''.join([i for i in x if not i.isdigit()])\n",
    "    return x\n",
    "print(remove_digits(\"hey1 boy! 123\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Anurag\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "############ installing stopwords     ############\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "########## removing stopwords    #########\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "def remove_stop_words(x):\n",
    "    x = ' '.join([i for i in x.lower().split(' ') if i not in stop])\n",
    "    return x\n",
    "#print(stop)\n",
    "print(remove_stop_words(\"i me myself am you're good\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mansi is a good girl\n"
     ]
    }
   ],
   "source": [
    "######## converting to lower case    #####\n",
    "def to_lower(x):\n",
    "    return x.lower()\n",
    "print(to_lower(\"MANSI IS A GOOD GIRL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle_missing_values - Basic data imputation of missing values\n",
    "def handle_missing_values(df):\n",
    "    df['dominant_color'].fillna(value='missing', inplace=True)\n",
    "    df['dominant_material'].fillna(value='None', inplace=True)\n",
    "    df['product_type'].fillna(value='None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_categorical - Converts Categorical Features \n",
    "def to_categorical(df):\n",
    "    df['brand'] = df['brand'].astype('category')\n",
    "    df['category'] = df['category'].astype('category')\n",
    "    #df['item_condition_id'] = df['item_condition_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### changing in_stock as shipping and others     ######\n",
    "#text = open(\"C:/Users/Anurag/Desktop/myntradata.csv\", \"r\")\n",
    "#text = ''.join([i for i in text]) \\\n",
    " #   .replace(\"In Stock\", \"0\") \\\n",
    "  #  .replace('Out of Stock','1')\n",
    "#x = open(\"C:/Users/Anurag/Desktop/final.csv\",\"w\")\n",
    "#x.writelines(text)\n",
    "#x.close()\n",
    "#read input file\n",
    "#import pandas as pd\n",
    "#import re\n",
    "#K=3\n",
    "#splt_char = \"/\"\n",
    "#df = pd.read_csv(\"C:/Users/Anurag/Desktop/myntradata.csv\")\n",
    "#df.head()\n",
    "#for i in range(len(df)):\n",
    "  #temp = df.loc[i,'category'].split(splt_char)\n",
    "  #res = splt_char.join(temp[:K]), splt_char.join(temp[K:])\n",
    "  #df.loc[i, 'category'] = res[0]\n",
    "#df.to_csv(\"C:/Users/Anurag/Desktop/myntradata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "################################################                     MY ML PART                  ########################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   product_id     size             brand dominant_material  \\\n",
       "0     6937673       XL             IMARA         Polyester   \n",
       "1     7441182       XL  House of Pataudi            cotton   \n",
       "2     9245141        S  The White Willow            Cotton   \n",
       "3     1314889  Onesize    Dupatta Bazaar           Chiffon   \n",
       "4     7705322        S          Manyavar              Silk   \n",
       "\n",
       "                                                name dominant_color  \\\n",
       "0                        IMARA Women Black Solid Top          Black   \n",
       "1  House of Pataudi Men Black Printed Straight Kurta          Black   \n",
       "2  The White Willow Unisex Off-White Therapedic M...          White   \n",
       "3                        Dupatta Bazaar Pink Dupatta           Pink   \n",
       "4  Manyavar Men Yellow & White Self Design Kurta ...         Yellow   \n",
       "\n",
       "          product_type                                    product_details  \\\n",
       "0                  Top  Black solid woven regular top,has a V-neck, th...   \n",
       "1       Straight Kurta  Black printed straight kurta, has a mandarin c...   \n",
       "2                  NaN  Set content: 1 pillow  Colour: Off white  Fill...   \n",
       "3              Dupatta             Pink dupatta&nbsp;with crinkled effect   \n",
       "4  Kurta with Churidar  Yellow and white self design kurta with churid...   \n",
       "\n",
       "                  category  price  shipping  \n",
       "0      Clothing/Women/Tops    959         1  \n",
       "1      Clothing/Men/Kurtas    799         0  \n",
       "2      Home/Unisex/Pillows   1399         0  \n",
       "3   Clothing/Women/Dupatta    349         0  \n",
       "4  Clothing/Men/Kurta Sets   2999         1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>size</th>\n      <th>brand</th>\n      <th>dominant_material</th>\n      <th>name</th>\n      <th>dominant_color</th>\n      <th>product_type</th>\n      <th>product_details</th>\n      <th>category</th>\n      <th>price</th>\n      <th>shipping</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6937673</td>\n      <td>XL</td>\n      <td>IMARA</td>\n      <td>Polyester</td>\n      <td>IMARA Women Black Solid Top</td>\n      <td>Black</td>\n      <td>Top</td>\n      <td>Black solid woven regular top,has a V-neck, th...</td>\n      <td>Clothing/Women/Tops</td>\n      <td>959</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7441182</td>\n      <td>XL</td>\n      <td>House of Pataudi</td>\n      <td>cotton</td>\n      <td>House of Pataudi Men Black Printed Straight Kurta</td>\n      <td>Black</td>\n      <td>Straight Kurta</td>\n      <td>Black printed straight kurta, has a mandarin c...</td>\n      <td>Clothing/Men/Kurtas</td>\n      <td>799</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9245141</td>\n      <td>S</td>\n      <td>The White Willow</td>\n      <td>Cotton</td>\n      <td>The White Willow Unisex Off-White Therapedic M...</td>\n      <td>White</td>\n      <td>NaN</td>\n      <td>Set content: 1 pillow  Colour: Off white  Fill...</td>\n      <td>Home/Unisex/Pillows</td>\n      <td>1399</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1314889</td>\n      <td>Onesize</td>\n      <td>Dupatta Bazaar</td>\n      <td>Chiffon</td>\n      <td>Dupatta Bazaar Pink Dupatta</td>\n      <td>Pink</td>\n      <td>Dupatta</td>\n      <td>Pink dupatta&amp;nbsp;with crinkled effect</td>\n      <td>Clothing/Women/Dupatta</td>\n      <td>349</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7705322</td>\n      <td>S</td>\n      <td>Manyavar</td>\n      <td>Silk</td>\n      <td>Manyavar Men Yellow &amp; White Self Design Kurta ...</td>\n      <td>Yellow</td>\n      <td>Kurta with Churidar</td>\n      <td>Yellow and white self design kurta with churid...</td>\n      <td>Clothing/Men/Kurta Sets</td>\n      <td>2999</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "\n",
    "train1= pd.read_csv('C:/Users/Anurag/Desktop/MLMINI/final.csv')\n",
    "train1.drop(['images','complete_the_look'],axis=1,inplace=True)\n",
    "train1.head()\n",
    "#len(train.columns)\n",
    "\n",
    "################# for changing category   #################\n",
    "\n",
    "splt_char = \"/\"\n",
    "K=3\n",
    "for i in range(len(train1)):\n",
    "    s=str(train1.loc[i, 'category'])\n",
    "    temp =s.split(splt_char)\n",
    "    res = splt_char.join(temp[:K]), splt_char.join(temp[K:])\n",
    "    train1.loc[i, 'category'] = res[0]\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "##########################################                     CATEGORIES                    ############################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   category category_sub1 category_sub2  price\n",
       "0  Clothing         Women          Tops    959\n",
       "1  Clothing           Men        Kurtas    799\n",
       "2      Home        Unisex       Pillows   1399\n",
       "3  Clothing         Women       Dupatta    349\n",
       "4  Clothing           Men    Kurta Sets   2999"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>category_sub1</th>\n      <th>category_sub2</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Clothing</td>\n      <td>Women</td>\n      <td>Tops</td>\n      <td>959</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Clothing</td>\n      <td>Men</td>\n      <td>Kurtas</td>\n      <td>799</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Home</td>\n      <td>Unisex</td>\n      <td>Pillows</td>\n      <td>1399</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Clothing</td>\n      <td>Women</td>\n      <td>Dupatta</td>\n      <td>349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clothing</td>\n      <td>Men</td>\n      <td>Kurta Sets</td>\n      <td>2999</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "#############  category wise distribution  ###########\n",
    "\n",
    "def transform_category_name(category):\n",
    "    try:\n",
    "        main, sub1, sub2= category.split('/')\n",
    "        return main, sub1, sub2\n",
    "    except:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "train1['category'], train1['category_sub1'], train1['category_sub2'] = zip(*train1['category'].apply(transform_category_name))\n",
    "cat_train = train1[['category','category_sub1','category_sub2', 'price']]\n",
    "cat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-45-4f4857f0d0c8>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  descr['count'] = descr['product_details'].apply(lambda x : len(str(x)))\n",
      "<ipython-input-45-4f4857f0d0c8>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  descr['product_details'] = descr['product_details'].apply(remove_digits)\n",
      "<ipython-input-45-4f4857f0d0c8>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  descr['product_details'] = descr['product_details'].apply(remove_punctuation)\n",
      "<ipython-input-45-4f4857f0d0c8>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  descr['product_details'] = descr['product_details'].apply(remove_stop_words)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     product_details  price  count\n",
       "0  black solid woven regular tophas vneck threequ...    959     85\n",
       "1  black printed straight kurta mandarin collar l...    799    107\n",
       "2  set content  pillow  colour white  filling mem...   1399    242\n",
       "3               pink dupattanbspwith crinkled effect    349     38\n",
       "4  yellow white self design kurta churidaryellow ...   2999    185"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_details</th>\n      <th>price</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>black solid woven regular tophas vneck threequ...</td>\n      <td>959</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>black printed straight kurta mandarin collar l...</td>\n      <td>799</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>set content  pillow  colour white  filling mem...</td>\n      <td>1399</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pink dupattanbspwith crinkled effect</td>\n      <td>349</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>yellow white self design kurta churidaryellow ...</td>\n      <td>2999</td>\n      <td>185</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "################        I am on 3d\n",
    "\n",
    "train1.product_details = train1.product_details.astype(str)\n",
    "\n",
    "descr = train1[['product_details', 'price']]\n",
    "descr['count'] = descr['product_details'].apply(lambda x : len(str(x)))\n",
    "\n",
    "descr['product_details'] = descr['product_details'].apply(remove_digits)\n",
    "descr['product_details'] = descr['product_details'].apply(remove_punctuation)\n",
    "descr['product_details'] = descr['product_details'].apply(remove_stop_words)\n",
    "\n",
    "descr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-46-10f86e2ca5b1>:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  descr['product_details'] = descr['product_details'].apply(porter.stem)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     product_details  price  count\n",
       "0  black solid woven regular tophas vneck threequ...    959     85\n",
       "1  black printed straight kurta mandarin collar l...    799    107\n",
       "2  set content  pillow  colour white  filling mem...   1399    242\n",
       "3               pink dupattanbspwith crinkled effect    349     38\n",
       "4  yellow white self design kurta churidaryellow ...   2999    185\n",
       "5  beige solid kurta pyjamas beige straight knee ...    979    165\n",
       "6  green coloured freesize dabu print cotton skir...   1572    153\n",
       "7  blue white printed aline kurta mandarin collar...    479    124\n",
       "8  maroon solid aline kurta round neck threequart...   1359     78\n",
       "9  orange white printed kurta pyjamas orange stra...    586    183"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_details</th>\n      <th>price</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>black solid woven regular tophas vneck threequ...</td>\n      <td>959</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>black printed straight kurta mandarin collar l...</td>\n      <td>799</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>set content  pillow  colour white  filling mem...</td>\n      <td>1399</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pink dupattanbspwith crinkled effect</td>\n      <td>349</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>yellow white self design kurta churidaryellow ...</td>\n      <td>2999</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>beige solid kurta pyjamas beige straight knee ...</td>\n      <td>979</td>\n      <td>165</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>green coloured freesize dabu print cotton skir...</td>\n      <td>1572</td>\n      <td>153</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>blue white printed aline kurta mandarin collar...</td>\n      <td>479</td>\n      <td>124</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>maroon solid aline kurta round neck threequart...</td>\n      <td>1359</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>orange white printed kurta pyjamas orange stra...</td>\n      <td>586</td>\n      <td>183</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "descr['product_details'] = descr['product_details'].apply(porter.stem)\n",
    "descr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['dominant_material', 'dominant_color', 'product_type'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "##############  check columns with missing values  dominant_material and color were missing ############\n",
    "train1.columns[train1.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the pre-processing functions\n",
    "\n",
    "handle_missing_values(train1)\n",
    "to_categorical(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   product_id     size             brand dominant_material  \\\n",
       "0     6937673       XL             IMARA         Polyester   \n",
       "1     7441182       XL  House of Pataudi            cotton   \n",
       "2     9245141        S  The White Willow            Cotton   \n",
       "3     1314889  Onesize    Dupatta Bazaar           Chiffon   \n",
       "4     7705322        S          Manyavar              Silk   \n",
       "\n",
       "                                                name dominant_color  \\\n",
       "0                        IMARA Women Black Solid Top          Black   \n",
       "1  House of Pataudi Men Black Printed Straight Kurta          Black   \n",
       "2  The White Willow Unisex Off-White Therapedic M...          White   \n",
       "3                        Dupatta Bazaar Pink Dupatta           Pink   \n",
       "4  Manyavar Men Yellow & White Self Design Kurta ...         Yellow   \n",
       "\n",
       "          product_type                                    product_details  \\\n",
       "0                  Top  Black solid woven regular top,has a V-neck, th...   \n",
       "1       Straight Kurta  Black printed straight kurta, has a mandarin c...   \n",
       "2                 None  Set content: 1 pillow  Colour: Off white  Fill...   \n",
       "3              Dupatta             Pink dupatta&nbsp;with crinkled effect   \n",
       "4  Kurta with Churidar  Yellow and white self design kurta with churid...   \n",
       "\n",
       "   category  price  shipping category_sub1 category_sub2  \n",
       "0  Clothing    959         1         Women          Tops  \n",
       "1  Clothing    799         0           Men        Kurtas  \n",
       "2      Home   1399         0        Unisex       Pillows  \n",
       "3  Clothing    349         0         Women       Dupatta  \n",
       "4  Clothing   2999         1           Men    Kurta Sets  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>size</th>\n      <th>brand</th>\n      <th>dominant_material</th>\n      <th>name</th>\n      <th>dominant_color</th>\n      <th>product_type</th>\n      <th>product_details</th>\n      <th>category</th>\n      <th>price</th>\n      <th>shipping</th>\n      <th>category_sub1</th>\n      <th>category_sub2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6937673</td>\n      <td>XL</td>\n      <td>IMARA</td>\n      <td>Polyester</td>\n      <td>IMARA Women Black Solid Top</td>\n      <td>Black</td>\n      <td>Top</td>\n      <td>Black solid woven regular top,has a V-neck, th...</td>\n      <td>Clothing</td>\n      <td>959</td>\n      <td>1</td>\n      <td>Women</td>\n      <td>Tops</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7441182</td>\n      <td>XL</td>\n      <td>House of Pataudi</td>\n      <td>cotton</td>\n      <td>House of Pataudi Men Black Printed Straight Kurta</td>\n      <td>Black</td>\n      <td>Straight Kurta</td>\n      <td>Black printed straight kurta, has a mandarin c...</td>\n      <td>Clothing</td>\n      <td>799</td>\n      <td>0</td>\n      <td>Men</td>\n      <td>Kurtas</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9245141</td>\n      <td>S</td>\n      <td>The White Willow</td>\n      <td>Cotton</td>\n      <td>The White Willow Unisex Off-White Therapedic M...</td>\n      <td>White</td>\n      <td>None</td>\n      <td>Set content: 1 pillow  Colour: Off white  Fill...</td>\n      <td>Home</td>\n      <td>1399</td>\n      <td>0</td>\n      <td>Unisex</td>\n      <td>Pillows</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1314889</td>\n      <td>Onesize</td>\n      <td>Dupatta Bazaar</td>\n      <td>Chiffon</td>\n      <td>Dupatta Bazaar Pink Dupatta</td>\n      <td>Pink</td>\n      <td>Dupatta</td>\n      <td>Pink dupatta&amp;nbsp;with crinkled effect</td>\n      <td>Clothing</td>\n      <td>349</td>\n      <td>0</td>\n      <td>Women</td>\n      <td>Dupatta</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7705322</td>\n      <td>S</td>\n      <td>Manyavar</td>\n      <td>Silk</td>\n      <td>Manyavar Men Yellow &amp; White Self Design Kurta ...</td>\n      <td>Yellow</td>\n      <td>Kurta with Churidar</td>\n      <td>Yellow and white self design kurta with churid...</td>\n      <td>Clothing</td>\n      <td>2999</td>\n      <td>1</td>\n      <td>Men</td>\n      <td>Kurta Sets</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   product_id     size             brand dominant_material  \\\n",
       "0     6937673       XL             IMARA         Polyester   \n",
       "1     7441182       XL  House of Pataudi            cotton   \n",
       "2     9245141        S  The White Willow            Cotton   \n",
       "3     1314889  Onesize    Dupatta Bazaar           Chiffon   \n",
       "4     7705322        S          Manyavar              Silk   \n",
       "\n",
       "                                                name dominant_color  \\\n",
       "0                        imara women black solid top          Black   \n",
       "1     house pataudi men black printed straight kurta          Black   \n",
       "2  white willow unisex offwhite therapedic memory...          White   \n",
       "3                        dupatta bazaar pink dupatta           Pink   \n",
       "4  manyavar men yellow  white self design kurta c...         Yellow   \n",
       "\n",
       "          product_type                                    product_details  \\\n",
       "0                  Top  black solid woven regular tophas vneck threequ...   \n",
       "1       Straight Kurta  black printed straight kurta mandarin collar l...   \n",
       "2                 None  set content  pillow  colour white  filling mem...   \n",
       "3              Dupatta               pink dupattanbspwith crinkled effect   \n",
       "4  Kurta with Churidar  yellow white self design kurta churidaryellow ...   \n",
       "\n",
       "   category  price  shipping category_sub1 category_sub2  \n",
       "0  Clothing    959         1         Women          Tops  \n",
       "1  Clothing    799         0           Men        Kurtas  \n",
       "2      Home   1399         0        Unisex       Pillows  \n",
       "3  Clothing    349         0         Women       Dupatta  \n",
       "4  Clothing   2999         1           Men    Kurta Sets  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>size</th>\n      <th>brand</th>\n      <th>dominant_material</th>\n      <th>name</th>\n      <th>dominant_color</th>\n      <th>product_type</th>\n      <th>product_details</th>\n      <th>category</th>\n      <th>price</th>\n      <th>shipping</th>\n      <th>category_sub1</th>\n      <th>category_sub2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6937673</td>\n      <td>XL</td>\n      <td>IMARA</td>\n      <td>Polyester</td>\n      <td>imara women black solid top</td>\n      <td>Black</td>\n      <td>Top</td>\n      <td>black solid woven regular tophas vneck threequ...</td>\n      <td>Clothing</td>\n      <td>959</td>\n      <td>1</td>\n      <td>Women</td>\n      <td>Tops</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7441182</td>\n      <td>XL</td>\n      <td>House of Pataudi</td>\n      <td>cotton</td>\n      <td>house pataudi men black printed straight kurta</td>\n      <td>Black</td>\n      <td>Straight Kurta</td>\n      <td>black printed straight kurta mandarin collar l...</td>\n      <td>Clothing</td>\n      <td>799</td>\n      <td>0</td>\n      <td>Men</td>\n      <td>Kurtas</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9245141</td>\n      <td>S</td>\n      <td>The White Willow</td>\n      <td>Cotton</td>\n      <td>white willow unisex offwhite therapedic memory...</td>\n      <td>White</td>\n      <td>None</td>\n      <td>set content  pillow  colour white  filling mem...</td>\n      <td>Home</td>\n      <td>1399</td>\n      <td>0</td>\n      <td>Unisex</td>\n      <td>Pillows</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1314889</td>\n      <td>Onesize</td>\n      <td>Dupatta Bazaar</td>\n      <td>Chiffon</td>\n      <td>dupatta bazaar pink dupatta</td>\n      <td>Pink</td>\n      <td>Dupatta</td>\n      <td>pink dupattanbspwith crinkled effect</td>\n      <td>Clothing</td>\n      <td>349</td>\n      <td>0</td>\n      <td>Women</td>\n      <td>Dupatta</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7705322</td>\n      <td>S</td>\n      <td>Manyavar</td>\n      <td>Silk</td>\n      <td>manyavar men yellow  white self design kurta c...</td>\n      <td>Yellow</td>\n      <td>Kurta with Churidar</td>\n      <td>yellow white self design kurta churidaryellow ...</td>\n      <td>Clothing</td>\n      <td>2999</td>\n      <td>1</td>\n      <td>Men</td>\n      <td>Kurta Sets</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "train1.product_details = train1.product_details.astype(str)\n",
    "\n",
    "train1['product_details'] = train1['product_details'].apply(remove_digits)\n",
    "train1['product_details'] = train1['product_details'].apply(remove_punctuation)\n",
    "train1['product_details'] = train1['product_details'].apply(remove_stop_words)\n",
    "train1['product_details'] = train1['product_details'].apply(to_lower)\n",
    "\n",
    "train1['name'] = train1['name'].apply(remove_digits)\n",
    "train1['name'] = train1['name'].apply(remove_punctuation)\n",
    "train1['name'] = train1['name'].apply(remove_stop_words)\n",
    "train1['name'] = train1['name'].apply(to_lower)\n",
    "\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "product_id           False\n",
       "size                 False\n",
       "brand                False\n",
       "dominant_material    False\n",
       "name                 False\n",
       "dominant_color       False\n",
       "product_type         False\n",
       "product_details      False\n",
       "category             False\n",
       "price                False\n",
       "shipping             False\n",
       "category_sub1        False\n",
       "category_sub2        False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "######### no column now has null values  #########\n",
    "\n",
    "train1.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################     creating a new category       ################################\n",
    "\n",
    "bins = [0, 1000, 25501]\n",
    "labels = ['less','more']\n",
    "train1['lt1000'] = pd.cut(train1['price'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   product_id     size             brand dominant_material  \\\n",
       "0     6937673       XL             IMARA         Polyester   \n",
       "1     7441182       XL  House of Pataudi            cotton   \n",
       "2     9245141        S  The White Willow            Cotton   \n",
       "3     1314889  Onesize    Dupatta Bazaar           Chiffon   \n",
       "4     7705322        S          Manyavar              Silk   \n",
       "\n",
       "                                                name dominant_color  \\\n",
       "0                        imara women black solid top          Black   \n",
       "1     house pataudi men black printed straight kurta          Black   \n",
       "2  white willow unisex offwhite therapedic memory...          White   \n",
       "3                        dupatta bazaar pink dupatta           Pink   \n",
       "4  manyavar men yellow  white self design kurta c...         Yellow   \n",
       "\n",
       "          product_type                                    product_details  \\\n",
       "0                  Top  black solid woven regular tophas vneck threequ...   \n",
       "1       Straight Kurta  black printed straight kurta mandarin collar l...   \n",
       "2                 None  set content  pillow  colour white  filling mem...   \n",
       "3              Dupatta               pink dupattanbspwith crinkled effect   \n",
       "4  Kurta with Churidar  yellow white self design kurta churidaryellow ...   \n",
       "\n",
       "   category  price  shipping category_sub1 category_sub2 lt1000  \n",
       "0  Clothing    959         1         Women          Tops   less  \n",
       "1  Clothing    799         0           Men        Kurtas   less  \n",
       "2      Home   1399         0        Unisex       Pillows   more  \n",
       "3  Clothing    349         0         Women       Dupatta   less  \n",
       "4  Clothing   2999         1           Men    Kurta Sets   more  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>size</th>\n      <th>brand</th>\n      <th>dominant_material</th>\n      <th>name</th>\n      <th>dominant_color</th>\n      <th>product_type</th>\n      <th>product_details</th>\n      <th>category</th>\n      <th>price</th>\n      <th>shipping</th>\n      <th>category_sub1</th>\n      <th>category_sub2</th>\n      <th>lt1000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6937673</td>\n      <td>XL</td>\n      <td>IMARA</td>\n      <td>Polyester</td>\n      <td>imara women black solid top</td>\n      <td>Black</td>\n      <td>Top</td>\n      <td>black solid woven regular tophas vneck threequ...</td>\n      <td>Clothing</td>\n      <td>959</td>\n      <td>1</td>\n      <td>Women</td>\n      <td>Tops</td>\n      <td>less</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7441182</td>\n      <td>XL</td>\n      <td>House of Pataudi</td>\n      <td>cotton</td>\n      <td>house pataudi men black printed straight kurta</td>\n      <td>Black</td>\n      <td>Straight Kurta</td>\n      <td>black printed straight kurta mandarin collar l...</td>\n      <td>Clothing</td>\n      <td>799</td>\n      <td>0</td>\n      <td>Men</td>\n      <td>Kurtas</td>\n      <td>less</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9245141</td>\n      <td>S</td>\n      <td>The White Willow</td>\n      <td>Cotton</td>\n      <td>white willow unisex offwhite therapedic memory...</td>\n      <td>White</td>\n      <td>None</td>\n      <td>set content  pillow  colour white  filling mem...</td>\n      <td>Home</td>\n      <td>1399</td>\n      <td>0</td>\n      <td>Unisex</td>\n      <td>Pillows</td>\n      <td>more</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1314889</td>\n      <td>Onesize</td>\n      <td>Dupatta Bazaar</td>\n      <td>Chiffon</td>\n      <td>dupatta bazaar pink dupatta</td>\n      <td>Pink</td>\n      <td>Dupatta</td>\n      <td>pink dupattanbspwith crinkled effect</td>\n      <td>Clothing</td>\n      <td>349</td>\n      <td>0</td>\n      <td>Women</td>\n      <td>Dupatta</td>\n      <td>less</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7705322</td>\n      <td>S</td>\n      <td>Manyavar</td>\n      <td>Silk</td>\n      <td>manyavar men yellow  white self design kurta c...</td>\n      <td>Yellow</td>\n      <td>Kurta with Churidar</td>\n      <td>yellow white self design kurta churidaryellow ...</td>\n      <td>Clothing</td>\n      <td>2999</td>\n      <td>1</td>\n      <td>Men</td>\n      <td>Kurta Sets</td>\n      <td>more</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "##########################################                     CHANGING TO INPUT VARIABLES                   ############################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################\n",
    "#########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<15000x460 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 107251 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# Applying Count Vectorizer to \"name\", this converts it into a sparse matrix \n",
    "\n",
    "cv = CountVectorizer(min_df=10)\n",
    "X_name = cv.fit_transform(train1['name'])\n",
    "X_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_name.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<15000x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15004 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Applying Count Vectorizer to \"category_name\", this converts it into a sparse matrix\n",
    "cv = CountVectorizer()\n",
    "X_category = cv.fit_transform(train1['category'])\n",
    "X_sub1 = cv.fit_transform(train1['category_sub1'])\n",
    "X_sub2 = cv.fit_transform(train1['category_sub2'])\n",
    "X_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n ...\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_category.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Applying TFIDF to \"product_details\"\n",
    "\n",
    "tv = TfidfVectorizer(max_features=55000, ngram_range=(1, 2), stop_words='english')\n",
    "X_description = tv.fit_transform(train1['product_details'])\n",
    "print(X_description.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Applying LabelBinarizer to \"brand_name\"\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb.fit_transform(train1['brand'])\n",
    "print(X_brand.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Applying LabelBinarizer to \"size\"\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_size= lb.fit_transform(train1['size'])\n",
    "print(X_size.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Applying LabelBinarizer to \"dominant_material\"\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_material= lb.fit_transform(train1['dominant_material'])\n",
    "print(X_material.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 0 ... 0 0 0]\n [0 1 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Applying LabelBinarizer to \"dominant_color\"\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_color= lb.fit_transform(train1['dominant_color'])\n",
    "print(X_color.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Applying LabelBinarizer to \"product_type\"\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_protype= lb.fit_transform(train1['product_type'].astype('str'))\n",
    "print(X_protype.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############        Creating our final sparse matrix   #############\n",
    "X_dummies = csr_matrix(pd.get_dummies(train1['shipping'], sparse=True).values)\n",
    "\n",
    "############## Combining everything together   #################\n",
    "sparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name,X_size,X_color,X_material,X_protype)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1]\n [1 0]\n [1 0]\n ...\n [0 1]\n [0 1]\n [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_dummies.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 1)\t1.0\n  (0, 631)\t0.18426797427868996\n  (0, 646)\t0.1969387613102637\n  (0, 1407)\t0.13291435708027\n  (0, 1526)\t0.1918886534674721\n  (0, 13023)\t0.19018205888698314\n  (0, 19066)\t0.17328940656430292\n  (0, 19111)\t0.4264151099736126\n  (0, 21100)\t0.05652818524240653\n  (0, 21114)\t0.2832183210048103\n  (0, 22329)\t0.08533297800444409\n  (0, 22489)\t0.19179712289066336\n  (0, 23903)\t0.0922384992926741\n  (0, 23921)\t0.09424063639220509\n  (0, 24197)\t0.3966280875276992\n  (0, 24199)\t0.4264151099736126\n  (0, 24904)\t0.17927468068743624\n  (0, 24935)\t0.20940467055285528\n  (0, 25957)\t0.1073080246636062\n  (0, 26061)\t0.2307186735018484\n  (0, 26657)\t1.0\n  (0, 26898)\t1.0\n  (0, 26945)\t1.0\n  (0, 27096)\t1.0\n  (0, 27293)\t1.0\n  :\t:\n  (9, 21591)\t0.14490096855773388\n  (9, 21778)\t0.07587990952985262\n  (9, 21921)\t0.19056345037574712\n  (9, 22329)\t0.07909784386859955\n  (9, 22443)\t0.15884958864653892\n  (9, 22772)\t0.13697049026680239\n  (9, 22788)\t0.0809177101024286\n  (9, 22816)\t0.12573602976872023\n  (9, 25538)\t0.23499027473124512\n  (9, 25634)\t0.17596060858519924\n  (9, 25660)\t0.1586918316752438\n  (9, 26778)\t1.0\n  (9, 26898)\t1.0\n  (9, 26956)\t1.0\n  (9, 27130)\t1.0\n  (9, 27191)\t1.0\n  (9, 27223)\t1.0\n  (9, 27227)\t1.0\n  (9, 27254)\t1.0\n  (9, 27302)\t1.0\n  (9, 27344)\t1.0\n  (9, 27396)\t1.0\n  (9, 27537)\t1.0\n  (9, 27557)\t1.0\n  (9, 27719)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(sparse_merge[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    6.866933\n",
       "1    6.684612\n",
       "2    7.244228\n",
       "3    5.857933\n",
       "4    8.006368\n",
       "Name: price, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# Create log price variable (Transformation)\n",
    "y = np.log1p(train1['price'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12000\n12000\n3000\n3000\n"
     ]
    }
   ],
   "source": [
    "train_x = train1[:12000]\n",
    "train_y = y[:12000]\n",
    "\n",
    "test_x = train1[12000:]\n",
    "test_y = y[12000:]\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = sparse_merge[:len(train_x)]\n",
    "X_test = sparse_merge[len(train_x):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60012\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1922\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [ 1200  1201  1202 ... 11997 11998 11999] and valid_index:  [   0    1    2 ... 1197 1198 1199]\n",
      "LGBM rmsle: 0.6586958504667046\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59794\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1931\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [1200 1201 1202 ... 2397 2398 2399]\n",
      "LGBM rmsle: 0.6602603714103489\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59803\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1943\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [2400 2401 2402 ... 3597 3598 3599]\n",
      "LGBM rmsle: 0.6657120080055954\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1919\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [3600 3601 3602 ... 4797 4798 4799]\n",
      "LGBM rmsle: 0.6507948829197943\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59946\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1926\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [4800 4801 4802 ... 5997 5998 5999]\n",
      "LGBM rmsle: 0.657685071725423\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59671\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1912\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [6000 6001 6002 ... 7197 7198 7199]\n",
      "LGBM rmsle: 0.6360716097687074\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59705\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1934\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [7200 7201 7202 ... 8397 8398 8399]\n",
      "LGBM rmsle: 0.6547257054272285\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60137\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1953\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [8400 8401 8402 ... 9597 9598 9599]\n",
      "LGBM rmsle: 0.6396238633378618\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59958\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1942\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [ 9600  9601  9602 ... 10797 10798 10799]\n",
      "LGBM rmsle: 0.6200561854067234\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59906\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 1937\n",
      "[LightGBM] [Info] Start training from score 7.824046\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 10797 10798 10799] and valid_index:  [10800 10801 10802 ... 11997 11998 11999]\n",
      "LGBM rmsle: 0.6044119571658806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################original#######################################################################################################################################################################################################################################\n",
    "\n",
    "kf = KFold(10,shuffle=False)\n",
    "for train_index, valid_index in kf.split(X_train_sparse):\n",
    "    X_train, y_train = X_train_sparse[train_index], y[train_index]\n",
    "    X_valid, y_valid = X_train_sparse[valid_index], y[valid_index]\n",
    "    d_train = lgb.Dataset(X_train, label=y_train)\n",
    "    params = {}\n",
    "    #params['learning_rate'] = 0.003\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'rmse'\n",
    "\n",
    "    clf = lgb.train(params, d_train, 100)\n",
    "   \n",
    "    lgbm_pred=clf.predict(X_valid)\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    print('[{}] LGBM completed.'.format(time.time() - start_time))\n",
    "    print(\"FOR train_index: \",train_index,\"and valid_index: \",valid_index)\n",
    "    print(\"LGBM rmsle: \"+str(rmsle(np.expm1(y_valid), np.expm1(lgbm_pred))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 989.23052135 1352.81973853 2285.54013995]\n",
      " [ 618.27059077  883.73504649 1735.53109143]\n",
      " [ 391.81532225  471.84801035 1421.91941281]\n",
      " ...\n",
      " [ 620.7218867   985.19261559 1822.59539521]\n",
      " [ 547.69383879  729.1278889  1552.59824935]\n",
      " [ 711.95567449  846.29918664 1037.89240652]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [ 1200  1201  1202 ... 11997 11998 11999] and valid_index:  [   0    1    2 ... 1197 1198 1199]\n",
      "LGBM rmsle: 0.35256028566326997\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 894.19998455 1335.38466516 2286.20646915]\n",
      " [ 642.74144708  908.2522971  1550.64082774]\n",
      " [ 435.78273697  557.68785179 1499.51688331]\n",
      " ...\n",
      " [ 618.79488814  942.76531963 1643.5569318 ]\n",
      " [ 547.41538867  733.80025054 1456.37351039]\n",
      " [ 750.9115762   857.18980423 1073.88183897]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [1200 1201 1202 ... 2397 2398 2399]\n",
      "LGBM rmsle: 0.3491141744059261\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 952.09255425 1386.67285389 2280.01951585]\n",
      " [ 561.3595085   875.32746031 1527.19890342]\n",
      " [ 401.17069822  522.30900844 1427.73450881]\n",
      " ...\n",
      " [ 614.25120868 1025.71714505 1732.46343775]\n",
      " [ 541.893095    722.01011234 1450.37958534]\n",
      " [ 708.53280225  834.70425074 1163.39114483]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [2400 2401 2402 ... 3597 3598 3599]\n",
      "LGBM rmsle: 0.3574965835864739\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 956.1354424  1378.55931846 2167.80247177]\n",
      " [ 586.34253811  855.36596023 1615.2504647 ]\n",
      " [ 367.19385542  513.02983395 1416.27140109]\n",
      " ...\n",
      " [ 628.43450527  990.66278889 1840.56207582]\n",
      " [ 559.81466006  747.14093947 1436.60369454]\n",
      " [ 716.38055806  843.87520748 1071.75351809]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [3600 3601 3602 ... 4797 4798 4799]\n",
      "LGBM rmsle: 0.38425727784078034\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 947.99519128 1316.45114176 2249.56030581]\n",
      " [ 634.11862446  921.6357539  1648.20004817]\n",
      " [ 382.69039888  495.81076961 1419.94498676]\n",
      " ...\n",
      " [ 620.4524122   968.48955046 1871.50208756]\n",
      " [ 571.78751351  743.88980352 1448.42442569]\n",
      " [ 757.09397335  878.95494541 1166.71997932]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [4800 4801 4802 ... 5997 5998 5999]\n",
      "LGBM rmsle: 0.3957389216538959\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 961.68141319 1383.42819634 2271.87357005]\n",
      " [ 654.91571834  868.06716114 1491.75319182]\n",
      " [ 386.53922134  547.97537723 1446.25526762]\n",
      " ...\n",
      " [ 621.26979003  940.66553304 1656.49919183]\n",
      " [ 546.01382786  759.25387013 1491.19884388]\n",
      " [ 721.80075222  847.01596888 1056.3262935 ]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [6000 6001 6002 ... 7197 7198 7199]\n",
      "LGBM rmsle: 0.3966709422234451\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 941.4948693  1308.50406502 2377.48567252]\n",
      " [ 597.58186945  704.38955014 1482.81646685]\n",
      " [ 380.31561617  563.97215023 1506.98776803]\n",
      " ...\n",
      " [ 601.83673     938.19594165 1804.47220046]\n",
      " [ 567.57723782  759.48938689 1324.00155489]\n",
      " [ 691.1868873   832.10840797 1141.21779492]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [7200 7201 7202 ... 8397 8398 8399]\n",
      "LGBM rmsle: 0.40617844005692894\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 925.39892445 1366.09595203 2291.05078395]\n",
      " [ 571.03415695  853.96647282 1618.42684559]\n",
      " [ 367.64040577  497.03848923 1457.95250754]\n",
      " ...\n",
      " [ 604.12681228 1053.07487224 1772.34241342]\n",
      " [ 550.00000064  758.7680182  1421.78659308]\n",
      " [ 724.47721303  854.14969899 1075.08818683]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [8400 8401 8402 ... 9597 9598 9599]\n",
      "LGBM rmsle: 0.3934747250456705\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 965.21102517 1367.68905115 2252.03645616]\n",
      " [ 605.66951232  891.43438918 1579.05606028]\n",
      " [ 375.47685683  524.2288008  1588.22286772]\n",
      " ...\n",
      " [ 596.78805853  983.44135532 1759.84439239]\n",
      " [ 543.64498884  740.43958901 1455.1156534 ]\n",
      " [ 679.45098867  851.12217678 1138.8925461 ]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [ 9600  9601  9602 ... 10797 10798 10799]\n",
      "LGBM rmsle: 0.41488553981686765\n",
      "\n",
      "prediction of quantile 0.1\n",
      "prediction of quantile 0.5\n",
      "prediction of quantile 0.9\n",
      "[[ 948.60498088 1314.0204053  2295.33416149]\n",
      " [ 611.5881061   839.9615462  1591.27795993]\n",
      " [ 386.1572942   509.70951731 1418.44109336]\n",
      " ...\n",
      " [ 578.23622374  920.22262986 1560.37765353]\n",
      " [ 545.16391385  717.21122037 1405.18231272]\n",
      " [ 695.32445575  888.01008601 1157.1003121 ]]\n",
      "[0.0] LGBM completed.\n",
      "FOR train_index:  [    0     1     2 ... 10797 10798 10799] and valid_index:  [10800 10801 10802 ... 11997 11998 11999]\n",
      "LGBM rmsle: 0.4178204515999549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10,shuffle=False)\n",
    "temp=0\n",
    "for train_index, valid_index in kf.split(X_train_sparse):\n",
    "    X_train, y_train = X_train_sparse[train_index], y[train_index]\n",
    "    X_valid, y_valid = X_train_sparse[valid_index], y[valid_index]\n",
    "    #d_train = lgb.Dataset(X_train, label=y_train)\n",
    "    params = {}\n",
    "    params['learning_rate'] = 0.1\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'quantile'\n",
    "    params['metric'] = 'quantile'\n",
    "    quantiles = [.1, .5, .9]\n",
    "   \n",
    "    lgbm_pred=np.zeros((len(valid_index),3))\n",
    "    pred=np.zeros((3000,3))\n",
    "  \n",
    "    for i in range(len(quantiles)):\n",
    "        print('prediction of quantile', quantiles[i])\n",
    "        lgb = LGBMRegressor(alpha=quantiles[i], **params)\n",
    "        model = lgb.fit(X_train, y_train)\n",
    "        lgbm_pred[:,i] = model.predict(X_valid)\n",
    "        pred[:,i]=model.predict(X_test)\n",
    "    \n",
    "    #print(lgbm_pred)\n",
    "    #print(pred)\n",
    "    print(np.expm1(pred))\n",
    "    if(temp==1):\n",
    "        final=np.expm1(pred)\n",
    "    temp=temp+1\n",
    "\n",
    "    ans=rmsle(np.expm1(y_valid), np.expm1(lgbm_pred[:,1]))\n",
    "    start_time = time.time()\n",
    "    print('[{}] LGBM completed.'.format(time.time() - start_time))\n",
    "    print(\"FOR train_index: \",train_index,\"and valid_index: \",valid_index)\n",
    "    print(\"LGBM rmsle: \"+str(ans))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 894.19998455 1335.38466516 2286.20646915]\n[ 642.74144708  908.2522971  1550.64082774]\n[ 435.78273697  557.68785179 1499.51688331]\n[ 784.82091715 1238.49291963 2285.46171075]\n[ 497.78050039  617.1644014  1491.82544236]\n[ 596.91499708  958.74226308 1595.80435086]\n[ 495.9495218   782.91958509 1277.98198812]\n[1070.55120731 2304.37506853 5117.81481083]\n[ 897.47937007 2466.90686789 4451.95729234]\n[ 623.32102431  950.54747572 1671.53532658]\n[1649.45992387 2574.41735481 3755.71086155]\n[1381.54276236 2601.74531546 3369.16865846]\n[ 591.00300187  947.28597183 1809.99841787]\n"
     ]
    }
   ],
   "source": [
    "print(final[0])\n",
    "print(final[1])\n",
    "print(final[2])\n",
    "print(final[3])\n",
    "print(final[4])\n",
    "print(final[5])\n",
    "print(final[58])\n",
    "print(final[59])\n",
    "print(final[60])\n",
    "print(final[61])\n",
    "print(final[62])\n",
    "print(final[63])\n",
    "print(final[64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "934.9254313685782\n1119.170179329013\n436.35043741529995\n550.7256784612986\n1072.9624515179446\n583.2567071362687\n609.2127863227583\n963.2792533826488\n684.7641687758537\n702.7129819856549\n687.4998762039954\n752.6135742570108\n1045.7321985431124\n648.3355726865311\n586.9900650400284\n590.6850860657028\n627.0495035496718\n1010.35960416753\n864.0751485956686\n737.2491738192988\n750.6112509281154\n1087.5217546885233\n620.7314082937229\n565.6746480829415\n1475.1010291506764\n535.5993356082816\n907.9788086569016\n625.9592935572931\n"
     ]
    }
   ],
   "source": [
    "print(final[16][0])\n",
    "print(final[28][0])\n",
    "print(final[34][0])\n",
    "print(final[17][0])\n",
    "print(final[20][0])\n",
    "print(final[24][0])\n",
    "print(final[43][0])\n",
    "print(final[46][0])\n",
    "print(final[33][0])\n",
    "print(final[15][0])\n",
    "print(final[29][0])\n",
    "print(final[30][0])\n",
    "print(final[32][0])\n",
    "print(final[35][0])\n",
    "print(final[13][0])\n",
    "print(final[14][0])\n",
    "print(final[21][0])\n",
    "print(final[26][0])\n",
    "print(final[48][0])\n",
    "print(final[49][0])\n",
    "print(final[25][0])\n",
    "print(final[19][0])\n",
    "print(final[18][0])\n",
    "print(final[22][0])\n",
    "print(final[23][0])\n",
    "print(final[27][0])\n",
    "print(final[31][0])\n",
    "print(final[47][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1295.8973034711828\n1582.1568347668888\n646.1439781308179\n647.3983230688003\n1639.7700960910522\n2342.5349319648\n763.7313449351021\n1654.9656357056667\n2182.7363672416714\n921.6950615021955\n1213.7648826644377\n1187.8905468244925\n2623.278722398886\n2511.420628187367\n1872.6617415948926\n787.9298858294254\n856.4502234183344\n2140.297824592159\n992.321985474588\n1110.249179213107\n877.811396498879\n1997.9589378591936\n823.1047360406981\n650.6198120513953\n3120.434173737805\n813.5553640980672\n1338.1289886652337\n797.8749175938227\n"
     ]
    }
   ],
   "source": [
    "print(final[16][1])\n",
    "print(final[28][1])\n",
    "print(final[34][1])\n",
    "print(final[17][1])\n",
    "print(final[20][1])\n",
    "print(final[24][1])\n",
    "print(final[43][1])\n",
    "print(final[46][1])\n",
    "print(final[33][1])\n",
    "print(final[15][1])\n",
    "print(final[29][1])\n",
    "print(final[30][1])\n",
    "print(final[32][1])\n",
    "print(final[35][1])\n",
    "print(final[13][1])\n",
    "print(final[14][1])\n",
    "print(final[21][1])\n",
    "print(final[26][1])\n",
    "print(final[48][1])\n",
    "print(final[49][1])\n",
    "print(final[25][1])\n",
    "print(final[19][1])\n",
    "print(final[18][1])\n",
    "print(final[22][1])\n",
    "print(final[23][1])\n",
    "print(final[27][1])\n",
    "print(final[31][1])\n",
    "print(final[47][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1816.1162444603829\n4969.152389736685\n1122.1578150020844\n1324.5511664706887\n3421.1465666190256\n4758.146385146272\n1727.6572155399529\n2529.902661297887\n4578.968210655175\n1647.463341584755\n1807.247100963532\n2783.3937960577196\n3817.9470965362334\n6583.875575201719\n5189.9704740315565\n1367.0925268935362\n1811.3609738326088\n4107.546835978464\n1815.0362936851345\n1630.350176693883\n1415.5267379605243\n3943.832141215754\n1459.3076260570674\n1885.365440823731\n3811.6505042950103\n2254.9623039076405\n2024.9259649295514\n1246.0136926642983\n"
     ]
    }
   ],
   "source": [
    "print(final[16][2])\n",
    "print(final[28][2])\n",
    "print(final[34][2])\n",
    "print(final[17][2])\n",
    "print(final[20][2])\n",
    "print(final[24][2])\n",
    "print(final[43][2])\n",
    "print(final[46][2])\n",
    "print(final[33][2])\n",
    "print(final[15][2])\n",
    "print(final[29][2])\n",
    "print(final[30][2])\n",
    "print(final[32][2])\n",
    "print(final[35][2])\n",
    "print(final[13][2])\n",
    "print(final[14][2])\n",
    "print(final[21][2])\n",
    "print(final[26][2])\n",
    "print(final[48][2])\n",
    "print(final[49][2])\n",
    "print(final[25][2])\n",
    "print(final[19][2])\n",
    "print(final[18][2])\n",
    "print(final[22][2])\n",
    "print(final[23][2])\n",
    "print(final[27][2])\n",
    "print(final[31][2])\n",
    "print(final[47][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1592.0000000000005\n1299.0\n648.9999999999999\n998.9999999999998\n764.0\n808.9999999999998\n1329.0000000000002\n2698.999999999999\n3498.9999999999995\n1598.9999999999998\n2798.9999999999995\n3498.9999999999995\n998.9999999999998\n"
     ]
    }
   ],
   "source": [
    "print(np.expm1(test_y[12000]))\n",
    "print(np.expm1(test_y[12001]))\n",
    "print(np.expm1(test_y[12002]))\n",
    "print(np.expm1(test_y[12003]))\n",
    "print(np.expm1(test_y[12004]))\n",
    "print(np.expm1(test_y[12005]))\n",
    "print(np.expm1(test_y[12058]))\n",
    "print(np.expm1(test_y[12059]))\n",
    "print(np.expm1(test_y[12060]))\n",
    "print(np.expm1(test_y[12061]))\n",
    "print(np.expm1(test_y[12062]))\n",
    "print(np.expm1(test_y[12063]))\n",
    "print(np.expm1(test_y[12064]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1499.0\n1319.0\n599.0\n629.0000000000001\n1795.0000000000007\n1485.0000000000002\n755.9999999999998\n2998.9999999999977\n2998.9999999999977\n782.9999999999998\n1998.9999999999998\n696.0000000000001\n1838.9999999999993\n3499.9999999999977\n3359.999999999999\n1118.9999999999998\n523.9999999999999\n3199.9999999999986\n808.9999999999998\n1039.0\n599.0\n5599.000000000005\n1695.0000000000002\n638.9999999999999\n2399.0000000000005\n1128.9999999999995\n2009.0000000000005\n719.0000000000001\n"
     ]
    }
   ],
   "source": [
    "print(np.expm1(test_y[12016]))\n",
    "print(np.expm1(test_y[12028]))\n",
    "print(np.expm1(test_y[12034]))\n",
    "print(np.expm1(test_y[12017]))\n",
    "print(np.expm1(test_y[12020]))\n",
    "print(np.expm1(test_y[12024]))\n",
    "print(np.expm1(test_y[12043]))\n",
    "print(np.expm1(test_y[12046]))\n",
    "print(np.expm1(test_y[12033]))\n",
    "print(np.expm1(test_y[12015]))\n",
    "print(np.expm1(test_y[12029]))\n",
    "print(np.expm1(test_y[12030]))\n",
    "print(np.expm1(test_y[12032]))\n",
    "print(np.expm1(test_y[12035]))\n",
    "print(np.expm1(test_y[12013]))\n",
    "print(np.expm1(test_y[12014]))\n",
    "print(np.expm1(test_y[12021]))\n",
    "print(np.expm1(test_y[12026]))\n",
    "print(np.expm1(test_y[12048]))\n",
    "print(np.expm1(test_y[12049]))\n",
    "print(np.expm1(test_y[12025]))\n",
    "print(np.expm1(test_y[12019]))\n",
    "print(np.expm1(test_y[12018]))\n",
    "print(np.expm1(test_y[12022]))\n",
    "print(np.expm1(test_y[12023]))\n",
    "print(np.expm1(test_y[12027]))\n",
    "print(np.expm1(test_y[12031]))\n",
    "print(np.expm1(test_y[12047]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Ridge Model\n",
      "[0.8896963596343994] Ridge completed.\n",
      "FOR train_index:  [ 1200  1201  1202 ... 11997 11998 11999] and valid_index:  [   0    1    2 ... 1197 1198 1199]\n",
      "Ridge rmsle: 0.3831553444294702\n",
      "Fitting Ridge Model\n",
      "[0.36742615699768066] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [1200 1201 1202 ... 2397 2398 2399]\n",
      "Ridge rmsle: 0.383893960074313\n",
      "Fitting Ridge Model\n",
      "[0.44581079483032227] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [2400 2401 2402 ... 3597 3598 3599]\n",
      "Ridge rmsle: 0.38272745562527805\n",
      "Fitting Ridge Model\n",
      "[0.4228975772857666] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [3600 3601 3602 ... 4797 4798 4799]\n",
      "Ridge rmsle: 0.38324390581544915\n",
      "Fitting Ridge Model\n",
      "[0.3869929313659668] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [4800 4801 4802 ... 5997 5998 5999]\n",
      "Ridge rmsle: 0.383092488732823\n",
      "Fitting Ridge Model\n",
      "[0.42189764976501465] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [6000 6001 6002 ... 7197 7198 7199]\n",
      "Ridge rmsle: 0.3831577762161335\n",
      "Fitting Ridge Model\n",
      "[0.5325517654418945] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [7200 7201 7202 ... 8397 8398 8399]\n",
      "Ridge rmsle: 0.3830865020342269\n",
      "Fitting Ridge Model\n",
      "[0.36305785179138184] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [8400 8401 8402 ... 9597 9598 9599]\n",
      "Ridge rmsle: 0.38257116916229433\n",
      "Fitting Ridge Model\n",
      "[0.3809816837310791] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 11997 11998 11999] and valid_index:  [ 9600  9601  9602 ... 10797 10798 10799]\n",
      "Ridge rmsle: 0.38254482779849386\n",
      "Fitting Ridge Model\n",
      "[0.38799095153808594] Ridge completed.\n",
      "FOR train_index:  [    0     1     2 ... 10797 10798 10799] and valid_index:  [10800 10801 10802 ... 11997 11998 11999]\n",
      "Ridge rmsle: 0.3831241091859913\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10,shuffle=False)\n",
    "for train_index, valid_index in kf.split(X_train_sparse):\n",
    "    start_time = time.time()\n",
    "    model = Ridge(solver = \"sag\", fit_intercept=False)\n",
    "    print(\"Fitting Ridge Model\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    print('[{}] Ridge completed.'.format(time.time() - start_time))\n",
    "    print(\"FOR train_index: \",train_index,\"and valid_index: \",valid_index)\n",
    "    print(\"Ridge rmsle: \"+str(rmsle(np.expm1(y_valid), np.expm1(preds_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                name  shipping  \\\n",
       "0  Global Desi Mustard Printed Tunic         1   \n",
       "1                               name  shipping   \n",
       "2  Global Desi Mustard Printed Tunic         1   \n",
       "\n",
       "                                     product_details        brand  category  \\\n",
       "0  Taking the bright colours of summer and nature...  Global Desi  Clothing   \n",
       "1                                    product_details        brand  category   \n",
       "2  Taking the bright colours of summer and nature...  Global Desi  Clothing   \n",
       "\n",
       "   size    color  material  product_type  \n",
       "0   XXL  Mustard   viscose         Tunic  \n",
       "1  size    color  material  product_type  \n",
       "2   XXL  Mustard   viscose         Tunic  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>shipping</th>\n      <th>product_details</th>\n      <th>brand</th>\n      <th>category</th>\n      <th>size</th>\n      <th>color</th>\n      <th>material</th>\n      <th>product_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Global Desi Mustard Printed Tunic</td>\n      <td>1</td>\n      <td>Taking the bright colours of summer and nature...</td>\n      <td>Global Desi</td>\n      <td>Clothing</td>\n      <td>XXL</td>\n      <td>Mustard</td>\n      <td>viscose</td>\n      <td>Tunic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>name</td>\n      <td>shipping</td>\n      <td>product_details</td>\n      <td>brand</td>\n      <td>category</td>\n      <td>size</td>\n      <td>color</td>\n      <td>material</td>\n      <td>product_type</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Global Desi Mustard Printed Tunic</td>\n      <td>1</td>\n      <td>Taking the bright colours of summer and nature...</td>\n      <td>Global Desi</td>\n      <td>Clothing</td>\n      <td>XXL</td>\n      <td>Mustard</td>\n      <td>viscose</td>\n      <td>Tunic</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "traine = {'name':\"\",'shipping':\"\",'product_details':\"\",'brand':\"\",'category':\"\",'size':\"\",'color':\"\",'material':\"\",'product_type':\"\"}\n",
    "traine['name']=\"Global Desi Mustard Printed Tunic\"\n",
    "traine['shipping']=\"1\"\n",
    "traine['product_details']=\"Taking the bright colours of summer and nature, Global Desi inspires the Women of style and substance to experiment with a range of colours from sophisticated black to subtle pastels and vibrant shades. So match the shade to your personality! Mix and match from a variety of colours and prints for a feminine look, or a modern twist.\"\n",
    "traine['brand']=\"Global Desi\"\n",
    "traine['category']=\"Clothing\"\n",
    "traine['size']=\"XXL\"\n",
    "traine['color']=\"Mustard\"\n",
    "traine['material']=\"viscose\"\n",
    "traine['product_type']=\"Tunic\"\n",
    "\n",
    "from csv import writer\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)\n",
    "append_list_as_row('data.csv',traine.keys())\n",
    "append_list_as_row('data.csv',traine.values())\n",
    "train12= pd.read_csv('data.csv')\n",
    "#train12.drop(['images','complete_the_look'],axis=1,inplace=True)\n",
    "train12.head()\n",
    "#len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "LightGBMError",
     "evalue": "The number of features in data (72) is not the same as it was in training data (27860).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-3f4dd3232df4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0msparse_merge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dummies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_brand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_category\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_color\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_material\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_protype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_merge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   3140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3141\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3142\u001b[1;33m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[0m\u001b[0;32m   3143\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3144\u001b[0m                                  data_has_header, is_reshape)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    722\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_csr\u001b[1;34m(self, csr, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(csr, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    882\u001b[0m             \u001b[0mcsr_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterPredictForCSR(\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m                 \u001b[0mptr_indptr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: The number of features in data (72) is not the same as it was in training data (27860).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "to_categorical(train12)\n",
    "train12.product_details = train12.product_details.astype(str)\n",
    "\n",
    "train12['product_details'] = train12['product_details'].apply(remove_digits)\n",
    "train12['product_details'] = train12['product_details'].apply(remove_punctuation)\n",
    "train12['product_details'] = train12['product_details'].apply(remove_stop_words)\n",
    "train12['product_details'] = train12['product_details'].apply(to_lower)\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "train12['product_details'] = train12['product_details'].apply(porter.stem)\n",
    "\n",
    "train12['name'] = train12['name'].apply(remove_digits)\n",
    "train12['name'] = train12['name'].apply(remove_punctuation)\n",
    "train12['name'] = train12['name'].apply(remove_stop_words)\n",
    "train12['name'] = train12['name'].apply(to_lower)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_name = cv.fit_transform(train12['name'])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_category = cv.fit_transform(train12['category'])\n",
    "\n",
    "tv = TfidfVectorizer(max_features=55000, ngram_range=(1, 2), stop_words='english')\n",
    "X_description = tv.fit_transform(train12['product_details'])\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb.fit_transform(train12['brand'])\n",
    "X_size= lb.fit_transform(train12['size'])\n",
    "X_material= lb.fit_transform(train12['material'])\n",
    "X_color= lb.fit_transform(train12['color'])\n",
    "X_protype= lb.fit_transform(train12['product_type'])\n",
    "\n",
    "X_dummies = csr_matrix(pd.get_dummies(train12['shipping'], sparse=True).values)\n",
    "\n",
    "sparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name,X_size,X_color,X_material,X_protype)).tocsr()\n",
    "preds = clf.predict(sparse_merge)\n",
    "arr= np.expm1(preds)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}